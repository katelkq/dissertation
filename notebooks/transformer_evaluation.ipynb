{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fynesse import access, assess, address\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2layers = assess.eat_pickle('./data/pickle/memo.pickle')\n",
    "\n",
    "max_seq_len = 300\n",
    "\n",
    "# add <bos> and <eos> markers\n",
    "for model in model2layers.keys():\n",
    "    pad_len = max_seq_len - len(model2layers[model]) - 2\n",
    "    model2layers[model] = ['<bos>'] + model2layers[model] + ['<eos>'] + ['<pad>'] * pad_len\n",
    "\n",
    "# take note of all the tokens that have appeared\n",
    "all_tokens = set()\n",
    "\n",
    "for layers in model2layers.values():\n",
    "    for layer in layers:\n",
    "        all_tokens.add(layer)\n",
    "\n",
    "all_tokens = np.array(list(all_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(all_tokens)\n",
    "\n",
    "def model2seq(model):\n",
    "    layers = model2layers[model]\n",
    "    return le.transform(layers)\n",
    "\n",
    "def seq2token(seq):\n",
    "    return le.inverse_transform(seq)\n",
    "\n",
    "def token2model(token):\n",
    "    model2layers = assess.eat_pickle('./data/pickle/memo.pickle')\n",
    "    for model, layers in model2layers.items():\n",
    "        if token == layers:\n",
    "            return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2layers = assess.eat_pickle('./data/pickle/memo.pickle')\n",
    "layers2models = dict()\n",
    "\n",
    "for model, layers in model2layers.items():\n",
    "    layers2models[tuple(layers)] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = assess.eat_pickle('./data/pickle/seqs.pickle')\n",
    "tgts = assess.eat_pickle('./data/pickle/tgts.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_seq(seq):\n",
    "    memo = []\n",
    "\n",
    "    for (i, token) in enumerate(seq):\n",
    "        if token == '<bos>' or token == '<pad>':\n",
    "            continue\n",
    "        \n",
    "        if token == '<eos>': \n",
    "            return memo\n",
    "        \n",
    "        memo.append(token)\n",
    "        \n",
    "    return memo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = list(map(trim_seq, seqs))\n",
    "tgts = list(map(trim_seq, tgts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic programming implementation of LCS problem\n",
    "\n",
    "# Returns length of LCS for X[0..m-1], Y[0..n-1] \n",
    "def lcs(X, Y):\n",
    "    m = len(X)\n",
    "    n = len(Y)\n",
    "    L = [[0 for x in range(n+1)] for x in range(m+1)]\n",
    " \n",
    "    # Following steps build L[m+1][n+1] in bottom up fashion. Note\n",
    "    # that L[i][j] contains length of LCS of X[0..i-1] and Y[0..j-1] \n",
    "    for i in range(m+1):\n",
    "        for j in range(n+1):\n",
    "            if i == 0 or j == 0:\n",
    "                L[i][j] = 0\n",
    "            elif X[i-1] == Y[j-1]:\n",
    "                L[i][j] = L[i-1][j-1] + 1\n",
    "            else:\n",
    "                L[i][j] = max(L[i-1][j], L[i][j-1])\n",
    " \n",
    "    # Following code is used to print LCS\n",
    "    index = L[m][n]\n",
    " \n",
    "    # Create a character array to store the lcs string\n",
    "    lcs = [\"\"] * (index+1)\n",
    "    lcs[index] = \"\\0\"\n",
    " \n",
    "    # Start from the right-most-bottom-most corner and\n",
    "    # one by one store characters in lcs[]\n",
    "    i = m\n",
    "    j = n\n",
    "    while i > 0 and j > 0:\n",
    " \n",
    "        # If current character in X[] and Y are same, then\n",
    "        # current character is part of LCS\n",
    "        if X[i-1] == Y[j-1]:\n",
    "            lcs[index-1] = X[i-1]\n",
    "            i-=1\n",
    "            j-=1\n",
    "            index-=1\n",
    " \n",
    "        # If not same, then find the larger of two and\n",
    "        # go in the direction of larger value\n",
    "        elif L[i-1][j] > L[i][j-1]:\n",
    "            i-=1\n",
    "        else:\n",
    "            j-=1\n",
    " \n",
    "    return lcs[:-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion of target sequence predicted\n",
    "\n",
    "def ptsp(seq, tgt):\n",
    "    if len(seq) == 0: return 0\n",
    "    return len(lcs(seq, tgt)) / len(seq)\n",
    "\n",
    "# edit distance over seq length\n",
    "\n",
    "import editdistance\n",
    "def edsl(seq, tgt):\n",
    "    return editdistance.eval(seq, tgt) / len(tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "p_by_model = defaultdict(int)\n",
    "pp_by_model = defaultdict(list)\n",
    "pe_by_model = defaultdict(list)\n",
    "\n",
    "for seq, tgt in zip(seqs, tgts):\n",
    "    model = layers2models[tuple(tgt)]\n",
    "\n",
    "    if ptsp(seq, tgt) == 1: p_by_model[model] += 1\n",
    "\n",
    "    pp_by_model[model].append(ptsp(seq, tgt))\n",
    "    pe_by_model[model].append(edsl(seq, tgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg13: 6\n",
      "resnet50: 9\n",
      "vitl32: 4\n",
      "vith14: 4\n",
      "vgg11: 9\n",
      "swinb: 7\n",
      "swint: 4\n",
      "vitb32: 3\n",
      "mobilenet: 5\n",
      "unet: 11\n",
      "vgg19: 8\n",
      "vgg16: 18\n",
      "retinanet: 9\n"
     ]
    }
   ],
   "source": [
    "for model in pp_by_model.keys():\n",
    "    print(f'{model}: {p_by_model[model]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg13: 0.410\n",
      "resnet50: 0.490\n",
      "vitl32: 0.493\n",
      "vith14: 0.462\n",
      "vgg11: 0.469\n",
      "swinb: 0.424\n",
      "swint: 0.433\n",
      "vitb32: 0.435\n",
      "mobilenet: 0.341\n",
      "unet: 0.525\n",
      "vgg19: 0.437\n",
      "vgg16: 0.550\n",
      "retinanet: 0.454\n"
     ]
    }
   ],
   "source": [
    "for model in pp_by_model.keys():\n",
    "    print(f'{model}: {np.mean(pp_by_model[model]):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg13: 1.731\n",
      "resnet50: 0.951\n",
      "vitl32: 0.855\n",
      "vith14: 0.885\n",
      "vgg11: 1.909\n",
      "swinb: 0.920\n",
      "swint: 0.931\n",
      "vitb32: 0.925\n",
      "mobilenet: 0.949\n",
      "unet: 0.986\n",
      "vgg19: 1.453\n",
      "vgg16: 1.335\n",
      "retinanet: 0.919\n"
     ]
    }
   ],
   "source": [
    "for model in pe_by_model.keys():\n",
    "    print(f'{model}: {np.mean(pe_by_model[model]):.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
