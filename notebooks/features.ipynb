{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fynesse import access, assess, address\n",
    "\n",
    "from functools import partial\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import MODELS, EVENTS, SEEDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def print_grid_search_results(cv_results_):\n",
    "    print(tabulate(np.column_stack([cv_results_['params'], cv_results_['mean_test_score'], cv_results_['rank_test_score']]), headers=['params', 'score', 'rank']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def evaluate_feature(master_dict, featured_events, n_bins):\n",
    "\n",
    "    scores, scores_unseen = [], []\n",
    "\n",
    "    for i, seed in enumerate(SEEDS):\n",
    "        X = address.make_features(master_dict, featured_events, n_bins=n_bins, models=MODELS, n_samples=500)\n",
    "        scaler = StandardScaler().fit(X)\n",
    "        X = scaler.transform(X)\n",
    "\n",
    "        X, X_test_unseen = address.seed_split(X, seed_idx=i, n_seeds=len(SEEDS))\n",
    "\n",
    "        le = LabelEncoder().fit(MODELS)\n",
    "\n",
    "        y = list()\n",
    "        for model in MODELS:\n",
    "            y += [model] * 400\n",
    "        y = le.transform(y)\n",
    "\n",
    "        y_test_unseen = list()\n",
    "        for model in MODELS:\n",
    "            y_test_unseen += [model] * 100\n",
    "        y_test_unseen = le.transform(y_test_unseen)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors=3, p=2, weights='uniform')\n",
    "        \n",
    "        knn.fit(X_train, y_train)\n",
    "\n",
    "        scores.append(accuracy_score(y_test, knn.predict(X_test)))\n",
    "        scores_unseen.append(accuracy_score(y_test_unseen, knn.predict(X_test_unseen)))\n",
    "\n",
    "    scores = np.column_stack(scores)\n",
    "    scores_unseen = np.column_stack(scores_unseen)\n",
    "    \n",
    "    return scores, scores_unseen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load master dictionary for everything\n",
    "\n",
    "master_dict = assess.eat_pickle(f'./data/pickle/master.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for n_bins in [1,2,4,8,16,32,64]:\n",
    "    for featured_events in combinations(EVENTS, 4):\n",
    "        \n",
    "        row = [n_bins, featured_events]\n",
    "        scores, scores_unseen = evaluate_feature(master_dict, featured_events, n_bins)\n",
    "        \n",
    "        row += [np.mean(scores, axis=1)[0], np.mean(scores_unseen, axis=1)[0]]\n",
    "        results.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, columns=['n_bins', 'events', 'accuracy', 'accuracy_unseen'])\n",
    "df.to_csv('./data/features_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cache-misses',\n",
       " 'cache-references',\n",
       " 'L1-dcache-load-misses',\n",
       " 'fp_arith_inst_retired.256b_packed_single')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='accuracy', ascending=False).iloc[6]['events']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
